# Predictive_Autoscaling_MS_Thesis

Perfect ğŸŒ¸ â€” hereâ€™s a **ready-to-copy complete `README.md`** for your GitHub repository.
It includes everything: intro, setup, commands, results, and placeholders for screenshots.
Just copy and paste into your `README.md` file inside your project folder.

---

```markdown
# ğŸš€ Predictive Auto-Scaling Framework

This project implements a **Machine Learning-based Predictive Auto-Scaling System** that uses Alibaba Cloud traces to **proactively scale cloud resources** before latency degradation occurs.  
It integrates **LSTM**, **Random Forest (RF)**, and **ARIMA** models for forecasting and connects to a **Prometheusâ€“Grafana** monitoring stack for real-time visualization.

---

## ğŸ¯ Project Overview

### ğŸŒ©ï¸ Objective
To **predict workload behavior** and **scale resources intelligently** to maintain latency under the Service Level Objective (SLO) while minimizing cost.

### ğŸ§  Key Features
- Predictive scaling based on `mean + Ïƒ > SLO` rule  
- Trained models: **LSTM**, **Random Forest**, **ARIMA**
- Dynamic latency prediction (`response_time_p95`)
- Seamless observability using **Prometheus** and **Grafana**
- Real-time scaling control through **Docker Compose**

---

## ğŸ§° Tech Stack

| Category | Tools / Technologies |
|-----------|----------------------|
| **Languages** | Python, JavaScript (Node.js) |
| **ML Models** | LSTM (Keras), Random Forest (Sklearn), ARIMA (Statsmodels) |
| **Monitoring** | Prometheus, Grafana |
| **Containerization** | Docker & Docker Compose |
| **Dataset** | Alibaba Cloud Trace Logs (2000 sampled rows) |

---

## ğŸ§© Architecture

```

```
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚        Data Replay App        â”‚
      â”‚ (Replays Alibaba Cloud traces)â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚     Predictive Training Pipeline â”‚
      â”‚ (Feature Engg + LSTM/RF/ARIMA)  â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Predictive Controller (Î±Â·Ïƒ + mean)â”‚
      â”‚   Compares to SLO â†’ Scale Decision â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Prometheus + Grafana Monitoring Stack â”‚
 â”‚   Metrics, Dashboards, Alerts          â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```

---

## ğŸ“‚ Folder Structure

```

predictive-autoscaling/
â”œâ”€â”€ data/                  # Alibaba dataset samples
â”œâ”€â”€ artifacts/             # Model outputs and predictive_signal.json
â”œâ”€â”€ data-replay/           # Node.js replay service
â”œâ”€â”€ scaling-controller/    # Predictive controller (Node.js)
â”œâ”€â”€ monitoring/            # Prometheus, Grafana, Alertmanager configs
â”œâ”€â”€ docker-compose.yml     # Service orchestration
â””â”€â”€ train_pipeline.py      # ML training pipeline

````

---

## âš™ï¸ How to Run the Project

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/predictive-autoscaling.git
cd predictive-autoscaling
````

### 2ï¸âƒ£ Build and Start All Containers

```bash
docker compose up --build
```

This starts all services:
`app`, `scaling-controller`, `prometheus`, `grafana`, `alertmanager`, and `node-exporter`.

---

## ğŸŒ Access the Services

| Service                | URL                                                            | Description                       |
| ---------------------- | -------------------------------------------------------------- | --------------------------------- |
| **App Metrics**        | [http://localhost:8080/metrics](http://localhost:8080/metrics) | Replayed workload metrics         |
| **Prometheus**         | [http://localhost:9090](http://localhost:9090)                 | Metric collection and queries     |
| **Grafana**            | [http://localhost:3000](http://localhost:3000)                 | Dashboards (login: admin / admin) |
| **Alertmanager**       | [http://localhost:9093](http://localhost:9093)                 | Alert notifications               |
| **Controller Metrics** | [http://localhost:8082/metrics](http://localhost:8082/metrics) | Predictive scaling controller     |

---

## ğŸ“ˆ Watch Scaling Decisions in Real-Time

```bash
docker logs -f cloud1-scaling-controller-1 | egrep -E "predictive read|Initiating scaling|Scaling completed|Auto-scaling loop"
```

Youâ€™ll see logs like:

```
info: predictive read: mean=0.089 Ïƒ=0.003 decision=0.092 > threshold=0.09
info: Initiating scaling to 3 replicas
info: Scaling completed: 2 -> 3 replicas in 2s
```

---

## âš–ï¸ Manual Testing (Optional)

To simulate different conditions:

```bash
nano ./artifacts/predictive_signal.json
```

| Scenario       | Mean Value       | Expected Behavior   |
| -------------- | ---------------- | ------------------- |
| **Scale Up**   | `"mean": 0.095`  | Increases replicas  |
| **Scale Down** | `"mean": 0.070`  | Decreases replicas  |
| **No Scale**   | `"mean": 0.089"` | Keeps replicas same |

---

## ğŸ“Š Results & Evaluation

| Model             | MAE    | RMSE   | Comment                    |
| ----------------- | ------ | ------ | -------------------------- |
| **LSTM**          | 0.0040 | 0.0051 | Captures temporal patterns |
| **Random Forest** | 0.0002 | 0.0004 | Most accurate overall      |
| **ARIMA**         | 0.0046 | 0.0058 | Good baseline comparison   |

âœ… Scaling Controller successfully reacted to predicted latency by increasing replicas (e.g., `2 â†’ 3 â†’ 4`) before SLA breach.

---

## ğŸ“¸ Example Screenshots (add these)

ğŸ–¼ï¸ Prometheus Metrics Query
ğŸ–¼ï¸ Grafana Scaling Dashboard
ğŸ–¼ï¸ Controller Logs showing â€œScaling completed: 2 â†’ 3 replicasâ€

---

## ğŸ§  Future Enhancements

* Implement **Reinforcement Learning (RL)** for adaptive threshold tuning (dynamic Î±)
* Introduce **multi-metric scaling** (CPU, memory + latency)
* Add **cost-aware optimization** (replica vs SLA trade-off)
* Extend to **Kubernetes Horizontal Pod Autoscaler (HPA)** integration

---

## ğŸ§¹ Cleanup Commands

Stop all containers:

```bash
docker compose down
```

Remove everything (images, volumes, cache):

```bash
docker system prune -a --volumes
```

---

## ğŸ Conclusion

* Predictive scaling avoids performance degradation by forecasting workload.
* LSTM, RF, and ARIMA together ensure robust predictions.
* Prometheus + Grafana enable real-time observability.
* The system is generalizable and can integrate with modern DevOps stacks.

---

## ğŸ‘©â€ğŸ’» Author

**Chaithra Jagannatha Rao Telkar**
ğŸ“ Masterâ€™s Thesis Project â€” 2025
ğŸ“ Focus: Predictive Auto-Scaling in Cloud Computing
ğŸ’¡ Contact: [LinkedIn](#) | [GitHub](https://github.com/<your-username>)

```

---

Would you like me to generate a small **architecture diagram (image)** that fits this README section automatically (with clean labels like â€œPredictive Controllerâ€, â€œPrometheusâ€, â€œGrafanaâ€, etc.)?  
Itâ€™ll make your GitHub page visually stand out.
```


Excellent catch, Chaithra ğŸŒ¸ â€” yes, before running Docker, you need to **run the Python training pipeline** once to generate the **`predictive_signal.json`** file that your scaling controller reads.

Hereâ€™s how to add that clearly to your `README.md` ğŸ‘‡
(Iâ€™ll show the section you can just paste.)

---

### ğŸ§  3ï¸âƒ£ Run the Python Training Pipeline

Before starting Docker, you must train the predictive models and generate the **predictive signal file**.

Run this in your project root:

```bash
python3 vmcloud_pipeline_single.py --target response_time_p95 --epochs 30
```

âœ… This command:

* Loads and preprocesses the Alibaba dataset (`data/` folder)
* Builds lag and rolling features
* Trains **LSTM**, **Random Forest**, and **ARIMA** models
* Creates the output file â†’ `./artifacts/predictive_signal.json`

You should see output like:

```
[LSTM] saved: artifacts/lstm_model.keras
[RF] saved: artifacts/rf_model.pkl
[ARIMA] saved: artifacts/arima_model.pkl
ğŸ“ saved predictive signal -> artifacts/predictive_signal.json
```

---

Then, continue with:

```bash
docker compose up --build
```

---

If you want the exact README section ready to copy (with this added between step 2 and step 3 of your existing one), I can paste that version for you â€” want me to?
